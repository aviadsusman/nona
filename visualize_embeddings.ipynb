{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from models import NONA_FT, NONA\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from ft_cnn import RSNADataset\n",
    "from ft_transformer import AdressoDataset\n",
    "from utils import load_data_params, get_fold_indices\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torcheval.metrics.functional import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "path = 'results/rsna/models/03052236/dense_0.pth'\n",
    "path_split = path.split('/')\n",
    "dataset = path_split[1]\n",
    "model_type = path_split[-1][:-6]\n",
    "run = path_split[-2]\n",
    "seed = int(path_split[-1][-5])\n",
    "\n",
    "label = None\n",
    "if len(path_split) == 6:\n",
    "    label = path_split[2]\n",
    "\n",
    "pred_sim = model_type.split(\" \")\n",
    "if len(pred_sim)==2:\n",
    "    predictor_head = pred_sim[0]\n",
    "    sim = pred_sim[1]\n",
    "else:\n",
    "    predictor_head= model_type \n",
    "    sim = None\n",
    "\n",
    "if dataset == 'rsna':\n",
    "    feature_extractor = resnet18(weights='DEFAULT')\n",
    "elif dataset == 'adresso':\n",
    "    feature_extractor = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "model=NONA_FT(feature_extractor=feature_extractor, \n",
    "                        hl_sizes=[200,50], \n",
    "                        predictor=predictor_head, \n",
    "                        similarity=sim, \n",
    "                        task='binary', \n",
    "                        dtype=torch.float32,\n",
    "                        k = 11\n",
    "                        )                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_weights = torch.load(path, map_location=device)\n",
    "model.load_state_dict(sft_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'rsna':\n",
    "    task, data_df, fe, data_percentage, transform = load_data_params(dataset)\n",
    "    idx_dict = get_fold_indices(dataset=dataset, data_df=data_df, seed=seed, data_percentage=data_percentage, keep_unused=True)\n",
    "elif dataset == 'adresso':\n",
    "    task, data_df, fe, tokenizer = load_data_params(dataset, label=label)\n",
    "    idx_dict = get_fold_indices(dataset=dataset, label=label, data_df=data_df, seed=seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'rsna':\n",
    "    def collate(batch):\n",
    "        x, y = zip(*batch)\n",
    "        x = torch.stack(x).to(device).to(torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "        return x, y\n",
    "\n",
    "    train_dataset = RSNADataset(idx_dict['train'], transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False, collate_fn=collate)\n",
    "\n",
    "    unused_dataset = RSNADataset(idx_dict['unused'][: len(idx_dict['unused']) // 6], transform=transform, scaler=train_dataset.scaler)\n",
    "    unused_loader = DataLoader(unused_dataset, batch_size=len(unused_dataset), shuffle=False, collate_fn=collate)\n",
    "\n",
    "    test_dataset = RSNADataset(idx_dict['test'], transform=transform, scaler=train_dataset.scaler)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True, collate_fn=collate)\n",
    "\n",
    "\n",
    "elif dataset == 'adresso':\n",
    "    def collate_fn(batch):\n",
    "        input_ids = torch.tensor([item[\"input_ids\"] for item in batch])\n",
    "        attention_mask = torch.tensor([item[\"attention_mask\"] for item in batch])\n",
    "        labels = torch.tensor([item[\"labels\"] for item in batch], dtype=torch.float)\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "    \n",
    "    train_dataset = AdressoDataset(label=label, tokenizer=tokenizer, ids=idx_dict['train'])\n",
    "    train_loader = DataLoader(train_dataset.get_dataset(), batch_size=train_dataset.len(), shuffle=True, collate_fn=collate_fn) # for use as neighbors with val and test\n",
    "\n",
    "    val_dataset = AdressoDataset(label=label, tokenizer=tokenizer, ids=idx_dict['val'], scaler=train_dataset.scaler)\n",
    "    val_loader = DataLoader(val_dataset.get_dataset(), batch_size=val_dataset.len(), shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    test_dataset = AdressoDataset(label=label, tokenizer=tokenizer, scaler=train_dataset.scaler)\n",
    "    test_loader = DataLoader(test_dataset.get_dataset(), batch_size=test_dataset.len(), shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'rsna':\n",
    "    with torch.no_grad():\n",
    "        for (X_train, y_train), (X_test, y_test) in zip(train_loader, test_loader): # one batch\n",
    "            y_hat_train, train_embeddings = model(X_train, X_train, y_train, get_embeddings=True)\n",
    "            y_hat_test, test_embeddings = model(X_test, X_train, y_train, get_embeddings=True)\n",
    "\n",
    "elif dataset == 'adresso':\n",
    "    with torch.no_grad():\n",
    "        for train_batch, test_batch in zip(train_loader, test_loader):\n",
    "            X_train = {key: val.to(device) for key, val in train_batch.items() if key!='labels'}\n",
    "            y_train = train_batch['labels'].to(device)\n",
    "            \n",
    "            X_test = {key: val.to(device) for key, val in test_batch.items() if key!='labels'}\n",
    "            y_test = test_batch['labels'].to(device)\n",
    "            \n",
    "            y_hat_train, train_embeddings = model(X_train, X_train, y_train, get_embeddings=True)\n",
    "            y_hat_test, test_embeddings = model(X_test, X_train, y_train, get_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'rsna':\n",
    "    results_path = f\"results/{dataset}/scores_{run}.pkl\"\n",
    "elif dataset == 'adresso':\n",
    "    results_path = f\"results/{dataset}/{label}/scores_{run}.pkl\"\n",
    "\n",
    "with open(results_path, \"rb\") as file:\n",
    "    results = pkl.load(file=file)\n",
    "    desc = results[0]\n",
    "    scores_list = results[1:]\n",
    "print(desc)\n",
    "\n",
    "test_score = abs(scores_list[seed][f'{model_type} mlp'][0])\n",
    "test_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dim = 2\n",
    "\n",
    "embedding_set = 'train'\n",
    "if embedding_set == 'train':\n",
    "    embeddings = train_embeddings\n",
    "    label_dict = {'y_true': y_train, 'y_hat': y_hat_train, 'squared error': (y_hat_train - y_train)**2}    \n",
    "elif embedding_set == 'test':\n",
    "    embeddings = test_embeddings\n",
    "    label_dict = {'y_true': y_test, 'y_hat': y_hat_test, 'squared error': (y_hat_test - y_test)**2}\n",
    "\n",
    "proj_type = 'umap'\n",
    "if proj_type == 'tsne':\n",
    "    proj = TSNE(n_components=proj_dim, random_state=42)\n",
    "elif proj_type == 'pca':\n",
    "    proj = PCA(n_components=proj_dim, random_state=42)\n",
    "elif proj_type == 'umap':\n",
    "    proj = UMAP(n_components=proj_dim, random_state=42)\n",
    "\n",
    "reduced_embeddings = proj.fit_transform(embeddings)\n",
    "\n",
    "for label_to_vis, y in label_dict.items():\n",
    "    \n",
    "    title = f\"{proj_type.upper()} of {model_type} {embedding_set} embeddings colored by {label_to_vis} \\n test score = {test_score : 4f}\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))#, dpi=200)\n",
    "    if proj_dim == 2:\n",
    "        plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "        plt.colorbar(label=label_to_vis)\n",
    "        plt.title(title)\n",
    "\n",
    "    elif proj_dim == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], reduced_embeddings[:, 2], c=y, cmap='viridis', alpha=0.7)\n",
    "        fig.colorbar(ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], reduced_embeddings[:, 2], c=y, cmap='viridis', alpha=0.7), label=label_to_vis)\n",
    "        ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not the same as above. Outputs from above are with 50d NONA\n",
    "\n",
    "nona = NONA(dtype=torch.float32, batch_norm=2)\n",
    "grid_size = 500\n",
    "scale = 40\n",
    "\n",
    "x_grid = torch.linspace(-scale, scale, grid_size).to(torch.float32)\n",
    "y_grid = torch.linspace(-scale, scale, grid_size).to(torch.float32)\n",
    "\n",
    "X_test = torch.cartesian_prod(x_grid, y_grid)\n",
    "\n",
    "Z = nona(X_test, torch.tensor(reduced_embeddings), y_train).reshape(grid_size,grid_size).detach()\n",
    "\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection ='3d')\n",
    "ax.plot_wireframe(X_grid, Y_grid, Z, color ='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.linspace(-scale, scale, grid_size), np.linspace(-scale, scale, grid_size))\n",
    "grid_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "\n",
    "probabilities = nona(grid_points,  torch.tensor(reduced_embeddings), y_train).reshape(grid_size, grid_size).detach()\n",
    "\n",
    "# Plot the heatmap using contourf\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, probabilities, levels=20, cmap=\"coolwarm\", alpha=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
